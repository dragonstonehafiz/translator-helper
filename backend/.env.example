# Translator Helper Backend Configuration
# Copy this file to .env and fill in your values

# OpenAI (API)
OPENAI_API_KEY=
OPENAI_MODEL=gpt-4o
OPENAI_TEMPERATURE=0.5

# Whisper (Transcription)
WHISPER_MODEL=tiny
WHISPER_DEVICE=cuda:0  # Use 'cpu' if no GPU is available

# Llama.cpp (Local LLM)
# LLAMA_MODEL_FILE=qwen2.5-7b-instruct-q4_k_m.gguf
# LLAMA_N_CTX=4096
# LLAMA_N_GPU_LAYERS=-1
# LLAMA_N_THREADS=8
# LLAMA_TEMPERATURE=0.5
